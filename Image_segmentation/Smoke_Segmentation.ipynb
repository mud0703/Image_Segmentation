{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Smoke_Segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH2BfrnhqRuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "#!google-drive-ocamlfuse -cc\n",
        "# Remounting the drive every time, since the drive does not get updated\n",
        "\n",
        "#!pip3 install git+https://github.com/keras-team/keras.git -U\n",
        "#!pip install --trusted-host pypi.python.org moviepy\n",
        "\n",
        "\"\"\"Smoke Dect\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1cILBQO3PnBJu2LKIcD5MrK08kWtaRiUP\n",
        "\"\"\"\n",
        "#!pip install tensorflow==1.15.2\n",
        "# import libraries\n",
        "#%tensorflow_version 1.x\n",
        "#import tensorflow as tf\n",
        "#!pip install q keras==2.2.5\n",
        "\n",
        "#drive.mount('/content/drive', force_remount=True) # update drive \n",
        "\n",
        "import tensorflow as tf\n",
        "print('Tensorflow Version : ')\n",
        "print(tf.__version__)\n",
        "import keras\n",
        "#from keras import applications\n",
        "print(keras.__version__)\n",
        "\n",
        "\n",
        "#!git clone --branch r1.13.0 --depth 1 https://github.com/tensorflow/models\n",
        "\n",
        "#!tf_upgrade_v2 \\\n",
        "#  --infile drive/'My Drive'/'Colab Notebooks'/'Smoke Detection'.py \\\n",
        "#  --outfile /tmp/smokedetection_tfv2.py\n",
        "\n",
        "\n",
        "#import tensorflow as tf\n",
        "#x = tf.placeholder(shape=[None, 2], dtype=tf.float32)\n",
        "\n",
        "#import tensorflow.compat.v1 as tf\n",
        "#tf.disable_v2_behavior()\n",
        "#x = tf.placeholder(shape=[None, 2], dtype=tf.float32)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np # linear algebra\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from skimage.util import montage\n",
        "\n",
        "\n",
        "# ADDITIONAL DATASET FROM LABELBOX \n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import requests\n",
        "url_images=[]\n",
        "url_masks=[]\n",
        "r=[]\n",
        "\n",
        "\n",
        "# MAKING SURE LINKS ARE DOWNLOADABLE\n",
        "def is_downloadable(url):\n",
        "    \"\"\"\n",
        "    Does the url contain a downloadable resource\n",
        "    \"\"\"\n",
        "    h = requests.head(url, allow_redirects=True)\n",
        "    header = h.headers\n",
        "    content_type = header.get('content-type')\n",
        "    if 'text' in content_type.lower():\n",
        "        return False\n",
        "    if 'html' in content_type.lower():\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "# ............................\n",
        "\n",
        "server_csv='drive/My Drive/colab/labelleddata_labelbox.csv'\n",
        "local_csv='/home/aero/Dokumente/Documents/Uniper/ImageAnalysis/Smoke-semantic-segmentation/dataset-attempt3/labelleddata_labelbox.csv'\n",
        "server_images='/content/drive/My Drive/colab/dataset/train/images'\n",
        "local_images='/home/aero/Dokumente/Documents/Uniper/ImageAnalysis/Smoke-semantic-segmentation/dataset-attempt3/train/images'\n",
        "server_masks='/content/drive/My Drive/colab/dataset/train/masks'\n",
        "local_masks='/home/aero/Dokumente/Documents/Uniper/ImageAnalysis/Smoke-semantic-segmentation/dataset-attempt3/train/masks'\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "def add_dataset():\n",
        "  print('Adding more dataset . . .')\n",
        "  data=pd.read_csv(server_csv)\n",
        "  #data=pd.read_csv(local_csv)\n",
        "  for i in range(data.shape[0]):\n",
        "    url_images.append(data['Labeled Data'][i])\n",
        "    url_masks.append(re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',  data['Label'][i]))\n",
        "    for x in url_masks[i]:\n",
        "      if x is not '[' or ']':\n",
        "        url_masks[i]=x\n",
        "  # if url_masks[i] and url_images[i] and is_downloadable(url_masks[i]):\n",
        "    #if url_masks[i] and url_masks[i]!=[] and url_images[i] and is_downloadable(url_masks[i]) and i not in range(16,82) : # images from i=16 to 82 are invalid\n",
        "    if url_masks[i] and url_masks[i]!=[] and url_images[i] and is_downloadable(url_masks[i]) and i!=389 and i not in range(16,82) : # images from i=16 to 82 are invalid\n",
        "      print(i, 'IM+', url_images[i])\n",
        "      print(i, 'MSK+', url_masks[i])\n",
        "      print('.........................')\n",
        "      r= requests.get(url_images[i], allow_redirects=True)\n",
        "      r2= requests.get(url_masks[i], allow_redirects=True)\n",
        "      open(local_images+'/image'+str(i)+'.jpg', 'wb').write(r.content)\n",
        "      open(local_masks+'/image'+str(i)+'.jpg', 'wb').write(r2.content)\n",
        "  #print(r.headers.get('content-type'))\n",
        "  #print(r2.headers.get('content-type'))  \n",
        "  # ...............................\n",
        "  #MAKING TRANSPARENT LABELS BLACK \n",
        "  for i in range(data.shape[0]):\n",
        "    if url_masks[i] and url_masks[i]!=[] and url_images[i] and is_downloadable(url_masks[i]) and i!=389 and i not in range(16,82):\n",
        "      image = Image.open(local_masks+'/image'+str(i)+'.jpg')\n",
        "      new_image = Image.new(\"RGBA\", image.size, \"BLACK\") # Create a black rgba background\n",
        "      new_image.paste(image, (0, 0), image)              # Paste the image on the background. Go to the links given below for details.\n",
        "      new_image.convert('1').save(local_masks+'/image'+str(i)+'.jpg', \"JPEG\")\n",
        "  # ................................\n",
        "  \n",
        "#add_dataset()\n",
        "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
        "data_dir = 'drive/My Drive/colab/dataset'\n",
        "#data_dir='/home/aero/Dokumente/Documents/Uniper/ImageAnalysis/Smoke-semantic-segmentation/dataset-attempt3/'\n",
        "#train_image_dir = os.path.join(data_dir, 'train') # .../dataset/train\n",
        "train_image_dir = os.path.join(data_dir, 'train') # .../dataset/train\n",
        "print(train_image_dir)\n",
        "#test_image_dir = os.path.join(data_dir, 'train/images') # .../dataset/train/images\n",
        "test_image_dir = os.path.join(data_dir, 'train/images') # .../dataset/train/images\n",
        "print(test_image_dir)\n",
        "import gc; gc.enable() # memory is tight - Enables automatic garbage collector\n",
        "from skimage.morphology import label\n",
        "\n",
        "# Parameters to tune\n",
        "BATCH_SIZE = 4\n",
        "EDGE_CROP = 2\n",
        "NB_EPOCHS = 64\n",
        "GAUSSIAN_NOISE = 0.1\n",
        "UPSAMPLE_MODE = 'DECONV'\n",
        "# downsampling inside the network\n",
        "NET_SCALING = None\n",
        "# downsampling in preprocessing\n",
        "IMG_SCALING = (1, 1)\n",
        "# number of validation images to use\n",
        "VALID_IMG_COUNT = 400\n",
        "# maximum number of steps_per_epoch in training\n",
        "MAX_TRAIN_STEPS = 400\n",
        "AUGMENT_BRIGHTNESS = False\n",
        "\n",
        "def get_all_imgs():\n",
        "    img_path = os.path.join(train_image_dir,'images')\n",
        "    images = glob.glob(os.path.join(img_path,'*.*'))\n",
        "    return [os.path.basename(image) for image in images]\n",
        "\n",
        "# print(get_all_imgs())\n",
        "TRAIN_IMGS, TEST_IMGS = train_test_split(get_all_imgs()) # use default train test split (random order : 107 train images , 36 test images )\n",
        "\n",
        "import random\n",
        "def cv2_brightness_augment(img):\n",
        "    hsv = cv2.cvtColor(img,cv2.COLOR_RGB2HSV)\n",
        "    v = hsv[:,:,2]\n",
        "    seed = random.uniform(0.5,1.2)\n",
        "    v = (( v/255.0 ) * seed)*255.0\n",
        "    hsv[:,:,2] = np.array(np.clip(v,0,255),dtype=np.uint8)\n",
        "    rgb_final = cv2.cvtColor(hsv,cv2.COLOR_HSV2RGB)\n",
        "    return rgb_final\n",
        "\n",
        "def make_image_gen(img_file_list=TRAIN_IMGS, batch_size = BATCH_SIZE):\n",
        "    all_batches = TRAIN_IMGS\n",
        "    out_rgb = []\n",
        "    out_mask = []\n",
        "    img_path = os.path.join(train_image_dir,'images')\n",
        "    mask_path = os.path.join(train_image_dir,'masks')\n",
        "    while True:\n",
        "        np.random.shuffle(all_batches)\n",
        "        for c_img_id in all_batches:  # for an image in the training set\n",
        "            c_img = imread(os.path.join(img_path,c_img_id)) # read the image from the images dataset\n",
        "            c_img = cv2_brightness_augment(c_img)\n",
        "            c_mask = imread(os.path.join(mask_path,c_img_id)) # read the masked images from the prepared dataset (labelled data)\n",
        "            if IMG_SCALING is not None:\n",
        "                c_img = cv2.resize(c_img,(256,256),interpolation = cv2.INTER_AREA) # resize(source image, desired size, resampling using pixel area relation)\n",
        "                c_mask = cv2.resize(c_mask,(256,256),interpolation = cv2.INTER_AREA)\n",
        "            c_mask = np.reshape(c_mask,(c_mask.shape[0],c_mask.shape[1],-1)) # numpy.reshape(a, newshape, order='C')[source]\n",
        "            c_mask = c_mask > 0\n",
        "            out_rgb += [c_img]\n",
        "            out_mask += [c_mask]\n",
        "            if len(out_rgb)>=batch_size:\n",
        "                yield np.stack(out_rgb, 0)/255.0, np.stack(out_mask, 0) # yield function is just like return but keeps enough data to resume the function where it is left off\n",
        "                out_rgb, out_mask=[], []\n",
        "\n",
        "\"\"\"## Make Training Set\"\"\"\n",
        "train_gen = make_image_gen()\n",
        "train_x, train_y = next(train_gen)\n",
        "print('x', train_x.shape, train_x.min(), train_x.max()) # train_x=out_rgb size=256*256*3 (RGB) train_y=out_mask size=256*256*1 (black and white)\n",
        "print('y', train_y.shape, train_y.min(), train_y.max())\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (30, 10))\n",
        "batch_rgb = montage_rgb(train_x) #like a collage of training set\n",
        "batch_seg = montage(train_y[:, :, :, 0])\n",
        "ax1.imshow(batch_rgb)\n",
        "ax1.set_title('Images')\n",
        "ax2.imshow(batch_seg, cmap='gray')\n",
        "ax2.set_title('Segmentations')\n",
        "ax3.imshow(mark_boundaries(batch_rgb, \n",
        "                           batch_seg.astype(int)))\n",
        "ax3.set_title('Outlined Smokes')\n",
        "fig.savefig('overview.png')\n",
        "\n",
        "\"\"\"## Make Validation Set\"\"\"\n",
        "\n",
        "valid_x, valid_y = next(make_image_gen(TEST_IMGS,len(TEST_IMGS)))\n",
        "print('VALIDATION SHAPE')\n",
        "print(valid_x.shape, valid_y.shape)\n",
        "\n",
        "\"\"\"## Augment Data\"\"\"\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "dg_args = dict(featurewise_center = False, \n",
        "                  samplewise_center = False,\n",
        "                  rotation_range = 15, \n",
        "                  width_shift_range = 0.1, \n",
        "                  height_shift_range = 0.1, \n",
        "                  shear_range = 0.01,\n",
        "                  zoom_range = [0.9, 1.25],  \n",
        "                  horizontal_flip = True, \n",
        "                  vertical_flip = False,\n",
        "                  fill_mode = 'reflect',\n",
        "                   data_format = 'channels_last')\n",
        "# brightness can be problematic since it seems to change the labels differently from the images \n",
        "if AUGMENT_BRIGHTNESS:\n",
        "    dg_args[' brightness_range'] = [0.5, 1.5]\n",
        "image_gen = ImageDataGenerator(**dg_args)\n",
        "\n",
        "if AUGMENT_BRIGHTNESS:\n",
        "    dg_args.pop('brightness_range')\n",
        "label_gen = ImageDataGenerator(**dg_args)\n",
        "\n",
        "def create_aug_gen(in_gen, seed = None):\n",
        "    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n",
        "    for in_x, in_y in in_gen:\n",
        "        seed = np.random.choice(range(9999))\n",
        "        # keep the seeds syncronized otherwise the augmentation to the images is different from the masks\n",
        "        g_x = image_gen.flow(255*in_x, \n",
        "                             batch_size = in_x.shape[0], \n",
        "                             seed = seed, \n",
        "                             shuffle=True)\n",
        "        g_y = label_gen.flow(in_y, \n",
        "                             batch_size = in_x.shape[0], \n",
        "                             seed = seed, \n",
        "                             shuffle=True)\n",
        "\n",
        "        yield next(g_x)/255.0, next(g_y)\n",
        "\n",
        "cur_gen = create_aug_gen(train_gen)\n",
        "t_x, t_y = next(cur_gen)\n",
        "print('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\n",
        "print('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())\n",
        "# only keep first 9 samples to examine in detail\n",
        "t_x = t_x[:9]\n",
        "t_y = t_y[:9]\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n",
        "ax1.imshow(montage_rgb(t_x), cmap='gray')\n",
        "ax1.set_title('images')\n",
        "ax2.imshow(montage(t_y[:, :, :, 0]), cmap='gray')\n",
        "ax2.set_title('smoke')\n",
        "fig.savefig('augmentations.png')\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "\"\"\"## Build a Model\n",
        "### Here we use a slight deviation on the U-Net standard model\n",
        "\"\"\"\n",
        "\n",
        "from keras import models, layers\n",
        "\n",
        "def upsample_conv(filters, kernel_size, strides, padding):\n",
        "    return layers.Conv2DTranspose(filters, kernel_size, strides=strides, padding=padding)\n",
        "\n",
        "# needs clarification\n",
        "def upsample_simple(filters, kernel_size, strides, padding):\n",
        "    return layers.UpSampling2D(strides)\n",
        "\n",
        "if UPSAMPLE_MODE=='DECONV':\n",
        "    upsample=upsample_conv\n",
        "else:\n",
        "    upsample=upsample_simple\n",
        "    \n",
        "input_img = layers.Input(t_x.shape[1:], name = 'RGB_Input')\n",
        "pp_in_layer = input_img\n",
        "if NET_SCALING is not None:\n",
        "    pp_in_layer = layers.AvgPool2D(NET_SCALING)(pp_in_layer)\n",
        "    \n",
        "pp_in_layer = layers.GaussianNoise(GAUSSIAN_NOISE)(pp_in_layer)\n",
        "pp_in_layer = layers.BatchNormalization()(pp_in_layer)\n",
        "\n",
        "c1 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (pp_in_layer)\n",
        "c1 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (c1)\n",
        "p1 = layers.MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "c2 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (p1)\n",
        "c2 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (c2)\n",
        "p2 = layers.MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "c3 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (p2)\n",
        "c3 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (c3)\n",
        "p3 = layers.MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same') (p3)\n",
        "c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same') (c4)\n",
        "p4 = layers.MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "\n",
        "c5 = layers.Conv2D(256, (3, 3), activation='relu', padding='same') (p4)\n",
        "c5 = layers.Conv2D(256, (3, 3), activation='relu', padding='same') (c5)\n",
        "\n",
        "u6 = upsample(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "u6 = layers.concatenate([u6, c4])\n",
        "c6 = layers.Conv2D(128, (3, 3), activation='relu', padding='same') (u6)\n",
        "c6 = layers.Conv2D(128, (3, 3), activation='relu', padding='same') (c6)\n",
        "\n",
        "u7 = upsample(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "u7 = layers.concatenate([u7, c3])\n",
        "c7 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (u7)\n",
        "c7 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (c7)\n",
        "\n",
        "u8 = upsample(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "u8 = layers.concatenate([u8, c2])\n",
        "c8 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (u8)\n",
        "c8 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (c8)\n",
        "\n",
        "u9 = upsample(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "u9 = layers.concatenate([u9, c1], axis=3)\n",
        "c9 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (u9)\n",
        "c9 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (c9)\n",
        "\n",
        "d = layers.Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "d = layers.Cropping2D((EDGE_CROP, EDGE_CROP))(d)\n",
        "d = layers.ZeroPadding2D((EDGE_CROP, EDGE_CROP))(d)\n",
        "if NET_SCALING is not None:\n",
        "    d = layers.UpSampling2D(NET_SCALING)(d)\n",
        "\n",
        "seg_model = models.Model(inputs=[input_img], outputs=[d])\n",
        "seg_model.summary()\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import binary_crossentropy\n",
        "\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
        "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
        "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
        "def dice_p_bce(in_gt, in_pred):\n",
        "    return 1e-3*binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\n",
        "def true_positive_rate(y_true, y_pred):\n",
        "    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))/K.sum(y_true)\n",
        "seg_model.compile(optimizer=Adam(1e-4, decay=1e-6), loss=dice_p_bce, metrics=[dice_coef, 'binary_accuracy', true_positive_rate])\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
        "weight_path=\"{}_weights.best.hdf5\".format('seg_model')\n",
        "\n",
        "checkpoint = ModelCheckpoint(weight_path, monitor='val_dice_coef', verbose=1, \n",
        "                             save_best_only=True, mode='max', save_weights_only = True)\n",
        "\n",
        "reduceLROnPlat = ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, \n",
        "                                   patience=3, \n",
        "                                   verbose=1, mode='max', min_delta=0.0001, cooldown=2, min_lr=1e-6) # replaced epsilon with min_delta\n",
        "early = EarlyStopping(monitor=\"val_dice_coef\", \n",
        "                      mode=\"max\", \n",
        "                      patience=15) # probably needs to be more patient, but kaggle time is limited\n",
        "callbacks_list = [checkpoint, early, reduceLROnPlat]\n",
        "\n",
        "step_count = 128#min(MAX_TRAIN_STEPS, len(TRAIN_IMGS)//BATCH_SIZE)\n",
        "aug_gen = create_aug_gen(make_image_gen())\n",
        "val_gen = make_image_gen(TEST_IMGS, len(TEST_IMGS)//BATCH_SIZE)\n",
        "\n",
        "loss_history = [seg_model.fit_generator(aug_gen, \n",
        "                             steps_per_epoch=step_count, \n",
        "                             epochs=NB_EPOCHS, \n",
        "                             validation_data=val_gen,\n",
        "                             #validation_steps=100,\n",
        "                             validation_steps=len(TEST_IMGS)//BATCH_SIZE,\n",
        "                             callbacks=callbacks_list, \n",
        "                              workers=1 # the generator is not very thread safe\n",
        "                                       )]\n",
        "\n",
        "def show_loss(loss_history):\n",
        "    epich = np.cumsum(np.concatenate(\n",
        "        [np.linspace(0.5, 1, len(mh.epoch)) for mh in loss_history]))\n",
        "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(22, 10))\n",
        "    _ = ax1.plot(epich,\n",
        "                 np.concatenate([mh.history['loss'] for mh in loss_history]),\n",
        "                 'b-',\n",
        "                 epich, np.concatenate(\n",
        "            [mh.history['val_loss'] for mh in loss_history]), 'r-')\n",
        "    ax1.legend(['Training', 'Validation'])\n",
        "    ax1.set_title('Loss')\n",
        "\n",
        "    _ = ax2.plot(epich, np.concatenate(\n",
        "        [mh.history['true_positive_rate'] for mh in loss_history]), 'b-',\n",
        "                     epich, np.concatenate(\n",
        "            [mh.history['val_true_positive_rate'] for mh in loss_history]),\n",
        "                     'r-')\n",
        "    ax2.legend(['Training', 'Validation'])\n",
        "    ax2.set_title('True Positive Rate\\n(Positive Accuracy)')\n",
        "    \n",
        "    _ = ax3.plot(epich, np.concatenate(\n",
        "        [mh.history['binary_accuracy'] for mh in loss_history]), 'b-',\n",
        "                     epich, np.concatenate(\n",
        "            [mh.history['val_binary_accuracy'] for mh in loss_history]),\n",
        "                     'r-')\n",
        "    ax3.legend(['Training', 'Validation'])\n",
        "    ax3.set_title('Binary Accuracy (%)')\n",
        "    \n",
        "    _ = ax4.plot(epich, np.concatenate(\n",
        "        [mh.history['dice_coef'] for mh in loss_history]), 'b-',\n",
        "                     epich, np.concatenate(\n",
        "            [mh.history['val_dice_coef'] for mh in loss_history]),\n",
        "                     'r-')\n",
        "    ax4.legend(['Training', 'Validation'])\n",
        "    ax4.set_title('DICE')\n",
        "\n",
        "show_loss(loss_history)\n",
        "\n",
        "\n",
        "seg_model.load_weights(weight_path)\n",
        "seg_model.save('seg_model.h5')\n",
        "\n",
        "pred_y = seg_model.predict(valid_x)\n",
        "print(pred_y.shape, pred_y.min(), pred_y.max(), pred_y.mean())\n",
        "\n",
        "\"\"\"## Prepare Full Resolution Model\"\"\"\n",
        "\n",
        "# if IMG_SCALING is not None:\n",
        "#     fullres_model = models.Sequential()\n",
        "#     fullres_model.add(layers.AvgPool2D(IMG_SCALING, input_shape = (None, None, 3)))\n",
        "#     fullres_model.add(seg_model)\n",
        "#     fullres_model.add(layers.UpSampling2D(IMG_SCALING))\n",
        "# else:\n",
        "#     fullres_model = seg_model\n",
        "# fullres_model.save('fullres_model.h5')\n",
        "\n",
        "\"\"\"## Run the test data\"\"\"\n",
        "\n",
        "test_paths = os.listdir(test_image_dir)\n",
        "print(len(test_paths), 'test images found')\n",
        "fig, m_axs = plt.subplots(20, 2, figsize = (10, 40))\n",
        "[c_ax.axis('off') for c_ax in m_axs.flatten()]\n",
        "for (ax1, ax2), c_img_name in zip(m_axs, test_paths):\n",
        "    c_path = os.path.join(test_image_dir, c_img_name)\n",
        "    print(c_path)\n",
        "    if c_img_name.endswith('.jpg'):\n",
        "      try:\n",
        "        img = Image.open(c_path) # open the image file\n",
        "        img.verify() # verify that it is, in fact an image\n",
        "      except (IOError, SyntaxError) as e:\n",
        "        print('Bad file:', c_img_name)\n",
        "        os.remove(c_img_name)\n",
        "    c_img = imread(c_path)\n",
        "    c_img = cv2.resize(c_img,(256,256))\n",
        "    first_img = np.expand_dims(c_img, 0)/255.0\n",
        "    first_seg = seg_model.predict(first_img)\n",
        "    first_img[0][:,:,0] = (first_img[0][:,:,0]*0.7 + 0.5*first_seg[0, :, :, 0])\n",
        "    result = np.array(np.clip(first_img[0]*255.,0,255),dtype=np.int32)\n",
        "    ax1.imshow(result)\n",
        "    ax1.set_title('Image')\n",
        "    ax2.imshow(first_seg[0, :, :, 0], vmin = 0, vmax = 1, cmap='gray')\n",
        "    ax2.set_title('Prediction')\n",
        "fig.savefig('test_predictions.png')\n",
        "\n",
        "from moviepy.editor import VideoFileClip\n",
        "def process_image(image):\n",
        "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
        "    # TODO: put your pipeline here,\n",
        "    # you should return the final output (image where lines are drawn on lanes)\n",
        "    image_shape = image.shape[:2]\n",
        "#     print(image_shape)\n",
        "    image = cv2.resize(image,(256,256))\n",
        "    first_img = np.expand_dims(image, 0)/255.0\n",
        "#     result = image_pipeline(image)\n",
        "    first_seg = seg_model.predict(first_img)\n",
        "    first_img[0][:,:,0] = first_img[0][:,:,0]*0.7 + 0.3*first_seg[0, :, :, 0]\n",
        "    result = np.array(np.clip(first_img[0]*255,0,255),dtype=np.float)\n",
        "#     print(image_shape[:2],result.shape,type(result[0][0][0]))\n",
        "    result = cv2.resize(result,image_shape[::-1])\n",
        "#     result = result[...,::-1]\n",
        "    \n",
        "    return result\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "from itertools import count\n",
        "for i in count() : \n",
        "\n",
        "  name = input()\n",
        "  filename='/content/drive/My Drive/colab/Videos_to_test' + name\n",
        "  #filename='/home/aero/Dokumente/Documents/Uniper/ImageAnalysis/Smoke-semantic-segmentation/Output/Testing/Inputs/' + name\n",
        "  clip = VideoFileClip(filename)\n",
        "  white_clip = clip.fl_image(process_image)\n",
        "  %time white_clip.write_videofile('000_'+str(i)+'.mp4', audio=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}